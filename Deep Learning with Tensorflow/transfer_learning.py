# -*- coding: utf-8 -*-
"""Transfer Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GBYC-Fr70J5IixX9ozwgR6kE7FBQwWUL
"""

#!pip install -q -U "tensorflow-gpu==2.0.0b1"
from __future__ import absolute_import, division, print_function

import tensorflow as tf

import tensorflow_hub as hub
import numpy as np

print("Version:", tf.__version__)
print("Eager mode:",tf.executing_eagerly())
print("Hub version:", hub.__version__)
print("GPU is", "available" if tf.test.is_gpu_available() else "NOT AVAILABLE")
module_selection = ("mobilenet_v2", 224, 1280)
handle_base, pixels, FV_SIZE = module_selection
MODULE_HANDLE= "https://tfhub.dev/google/tf2-preview/{}/feature_vector/4".format(module_selection[0])
IMAGE_SIZE = (pixels, pixels)
print("Using {} with input size {} and output dimension {}".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))
import tensorflow_datasets as tfds
tfds.disable_progress_bar()

splits = tfds.Split.ALL.subsplit(weighted=(80,10,10))
splits, info = tfds.load("cats_vs_dogs", as_supervised=True, with_info=True, split=splits)

train_examples, validation_examples, test_examples = splits
num_examples = info.splits["train"].num_examples
num_classes = info.features["label"].num_classes

class_names = np.array(info.features["label"].names)

def format_image(image, label):
    #hub image expects its data normalized to the range [0,1]
    image = tf.image.resize(image, IMAGE_SIZE)/255.0
    return image, label

BATCH_SIZE = 32
train_batches = train_examples.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)
validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)
test_batches = test_examples.map(format_image).batch(1)
#for image_batch, label_batch in train_batches.take(1):
 #   pass
#image_batch.shape

feature_extractor = hub.KerasLayer(MODULE_HANDLE,
                                   input_shape = IMAGE_SIZE + (3,),
                                   output_shape=FV_SIZE,
                                   )
feature_extractor.trainable = False

print("Building  model with", MODULE_HANDLE)
model = tf.keras.Sequential([
                             feature_extractor,
                             tf.keras.layers.Dense(2, activation = "softmax")
])
model.summary()

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"])

EPOCHS = 5
hist = model.fit(train_batches, epochs=EPOCHS,
                 validation_data=validation_batches)

CATS_VS_DOGS_SAVED_MODEL = "exp_saved_model"
tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)

# Commented out IPython magic to ensure Python compatibility.
# %%bash -s $CATS_VS_DOGS_SAVED_MODEL
# saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default

loaded = tf.saved_model.load(CATS_VS_DOGS_SAVED_MODEL)
converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)

converter.optimizations = [tf.lite.Optimize.DEFAULT]

def representative_data_gen():
    for input_value, _ in test_batches.take(100):
        yield [input_value]

converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

tflite_model = converter.convert()

tflite_model_file = "converted_model.tflite"
with open(tflite_model_file, "wb") as f:
    f.write(tflite_model)

interpreter = tf.lite.Interpreter(model_path = tflite_model_file)
interpreter.allocate_tensors()
input_index = interpreter.get_input_details()[0]["index"]
output_index = interpreter.get_output_details()[0]["index"]

from tqdm import tqdm

predictions = []
test_labels, test_imgs = [], []
for img, label in tqdm(test_batches.take(10)):
    interpreter.set_tensor(input_index, img)
    interpreter.invoke()
    predictions.append(interpreter.get_tensor(output_index))
	
    test_labels.append(label.numpy()[0])
    test_imgs.append(img)

#from google.colab import files
#files.download("converted_model.tflite")

labels = ["cat", "dog"]
with open("labels.txt", "w") as f:
    f.write("\n".join(labels))
#files.download("labels.txt")